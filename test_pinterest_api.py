# # from selenium import webdriver

# # # ê°„ë‹¨ í…ŒìŠ¤íŠ¸
# # try:
# #     driver = webdriver.Chrome()
# #     driver.get("https://www.google.com")
# #     print("ChromeDriver ì„¤ì¹˜ ì„±ê³µ!")
# #     driver.quit()
# # except Exception as e:
# #     print(f"ChromeDriver ì„¤ì¹˜ í•„ìš”: {e}")

# from selenium import webdriver
# from selenium.webdriver.common.by import By
# import time
# import requests
# from bs4 import BeautifulSoup
# import json  # ê²°ê³¼ ì €ì¥ìš©

# class PinterestScraper:
#     def __init__(self):  # __init__ ì •í™•í•œ ë¬¸ë²• (ì–¸ë”ë°” 2ê°œì”©)
#         options = webdriver.ChromeOptions()
#         options.add_argument('--headless')
#         options.add_argument('--no-sandbox')
#         options.add_argument('--disable-dev-shm-usage')  # ì•ˆì •ì„± ê°œì„ 
#         self.driver = webdriver.Chrome(options=options)
        
#     def search_pins(self, query, max_pins=50):  # ì²˜ìŒì—” 50ê°œë¡œ í…ŒìŠ¤íŠ¸
#         search_url = f"https://www.pinterest.com/search/pins/?q={query}"
#         print(f"ê²€ìƒ‰ ì‹œì‘: {search_url}")
        
#         self.driver.get(search_url)
#         time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        
#         pins_data = []
#         last_height = self.driver.execute_script("return document.body.scrollHeight")
        
#         while len(pins_data) < max_pins:
#             self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
#             time.sleep(2)
            
#             pin_elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-test-id="pin"]')
#             print(f"í˜„ì¬ ì°¾ì€ í•€ ê°œìˆ˜: {len(pin_elements)}")
            
#             for pin in pin_elements[len(pins_data):]:
#                 try:
#                     img_element = pin.find_element(By.TAG_NAME, "img")
#                     img_url = img_element.get_attribute("src")
#                     img_alt = img_element.get_attribute("alt")
#                     pin_link = pin.find_element(By.TAG_NAME, "a").get_attribute("href")
                    
#                     pins_data.append({
#                         "image_url": img_url,
#                         "description": img_alt,
#                         "pin_url": pin_link
#                     })
                    
#                     print(f"ìˆ˜ì§‘ë¨ {len(pins_data)}: {img_alt[:50]}...")
                    
#                 except Exception as e:
#                     continue
                    
#             new_height = self.driver.execute_script("return document.body.scrollHeight")
#             if new_height == last_height:
#                 print("ë” ì´ìƒ ìƒˆë¡œìš´ ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")
#                 break
#             last_height = new_height
            
#         return pins_data[:max_pins]
    
#     def close(self):
#         self.driver.quit()

# # ì‹¤í–‰ ë° ê²°ê³¼ í™•ì¸
# if __name__ == "__main__":  # __name__ ì •í™•í•œ ë¬¸ë²• (ì–¸ë”ë°” 2ê°œì”©)
#     scraper = PinterestScraper()
#     try:
#         # ë‚¨ì ì—¬ë¦„ íŒ¨ì…˜ìœ¼ë¡œ ê²€ìƒ‰ (í•œêµ­ì–´)
#         pins = scraper.search_pins("ë‚¨ì ì—¬ë¦„ íŒ¨ì…˜", 20)  # ì²˜ìŒì—” 20ê°œë§Œ
        
#         # ê²°ê³¼ ì¶œë ¥
#         print(f"\nì´ {len(pins)}ê°œì˜ í•€ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")
        
#         # JSON íŒŒì¼ë¡œ ì €ì¥
#         with open("mens_summer_fashion_pins.json", "w", encoding="utf-8") as f:
#             json.dump(pins, f, ensure_ascii=False, indent=2)
        
#         print("ê²°ê³¼ê°€ mens_summer_fashion_pins.json íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
#         # ì²˜ìŒ 3ê°œë§Œ ë¯¸ë¦¬ë³´ê¸°
#         for i, pin in enumerate(pins[:3]):
#             print(f"\n{i+1}. {pin['description']}")
#             print(f"   ì´ë¯¸ì§€: {pin['image_url']}")
#             print(f"   ë§í¬: {pin['pin_url']}")
            
#     except Exception as e:
#         print(f"ì—ëŸ¬ ë°œìƒ: {e}")
#     finally:
#         scraper.close()
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
import requests
from bs4 import BeautifulSoup
import json
import random

class ImprovedPinterestScraper:
    def __init__(self):
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        self.driver = webdriver.Chrome(options=options)
        # ë´‡ ê°ì§€ ë°©ì§€
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
    def search_pins_improved(self, query, max_pins=50):
        search_url = f"https://www.pinterest.com/search/pins/?q={query}"
        print(f"ê²€ìƒ‰ ì‹œì‘: {search_url}")
        
        self.driver.get(search_url)
        time.sleep(5)  # ì´ˆê¸° ë¡œë”© ëŒ€ê¸°
        
        pins_data = []
        seen_urls = set()  # ì¤‘ë³µ ë°©ì§€
        scroll_attempts = 0
        max_scroll_attempts = 20
        no_new_content_count = 0
        
        while len(pins_data) < max_pins and scroll_attempts < max_scroll_attempts:
            # í˜„ì¬ í˜ì´ì§€ ë†’ì´ ê¸°ë¡
            last_height = self.driver.execute_script("return document.body.scrollHeight")
            
            # ìŠ¤í¬ë¡¤ ë‹¤ìš´
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            
            # ëœë¤ ëŒ€ê¸° (ë´‡ ê°ì§€ ë°©ì§€)
            time.sleep(random.uniform(3, 5))
            
            # ì¶”ê°€ ìŠ¤í¬ë¡¤ (Pinterest íŠ¹ì„±ìƒ ì—¬ëŸ¬ ë²ˆ ìŠ¤í¬ë¡¤ í•„ìš”)
            for i in range(3):
                self.driver.execute_script("window.scrollBy(0, 300);")
                time.sleep(1)
            
            # í•€ ìš”ì†Œë“¤ ì°¾ê¸°
            pin_elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-test-id="pin"]')
            print(f"ìŠ¤í¬ë¡¤ {scroll_attempts+1}: í˜ì´ì§€ì—ì„œ {len(pin_elements)}ê°œ í•€ ë°œê²¬")
            
            # ìƒˆë¡œìš´ í•€ ìˆ˜ì§‘
            new_pins_in_this_scroll = 0
            for pin in pin_elements:
                if len(pins_data) >= max_pins:
                    break
                    
                try:
                    img_element = pin.find_element(By.TAG_NAME, "img")
                    img_url = img_element.get_attribute("src")
                    
                    # ìœ íš¨í•œ ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸
                    if img_url and img_url.startswith('https') and img_url not in seen_urls:
                        img_alt = img_element.get_attribute("alt") or "No description"
                        
                        # Pinterest ê´‘ê³ ë‚˜ í”„ë¡œëª¨ì…˜ ì´ë¯¸ì§€ í•„í„°ë§
                        if "promoted" in img_alt.lower() or "ad" in img_alt.lower():
                            continue
                            
                        try:
                            pin_link = pin.find_element(By.TAG_NAME, "a").get_attribute("href")
                        except:
                            pin_link = "No link"
                        
                        pin_data = {
                            "image_url": img_url,
                            "description": img_alt,
                            "pin_url": pin_link,
                            "query": query,
                            "collected_at": time.strftime("%Y-%m-%d %H:%M:%S")
                        }
                        
                        pins_data.append(pin_data)
                        seen_urls.add(img_url)
                        new_pins_in_this_scroll += 1
                        
                        print(f"ìˆ˜ì§‘ë¨ {len(pins_data)}: {img_alt[:50]}...")
                        
                except Exception as e:
                    continue
            
            # ìƒˆë¡œìš´ ì½˜í…ì¸ ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
            new_height = self.driver.execute_script("return document.body.scrollHeight")
            
            if new_pins_in_this_scroll == 0:
                no_new_content_count += 1
                print(f"ìƒˆ í•€ ì—†ìŒ ({no_new_content_count}ë²ˆì§¸)")
                
                if no_new_content_count >= 3:
                    print("ì—°ì†ìœ¼ë¡œ ìƒˆ ì½˜í…ì¸ ê°€ ì—†ì–´ì„œ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    break
            else:
                no_new_content_count = 0  # ìƒˆ ì½˜í…ì¸  ë°œê²¬ì‹œ ë¦¬ì…‹
                
            scroll_attempts += 1
            
            # í˜ì´ì§€ ë†’ì´ê°€ ë³€í•˜ì§€ ì•Šìœ¼ë©´ ì¶”ê°€ ëŒ€ê¸°
            if new_height == last_height:
                print("í˜ì´ì§€ ë†’ì´ ë³€í™” ì—†ìŒ. ì¶”ê°€ ëŒ€ê¸°...")
                time.sleep(3)
        
        print(f"ìµœì¢… ìˆ˜ì§‘ ì™„ë£Œ: {len(pins_data)}ê°œ")
        return pins_data
    
    def multi_query_search(self, queries, pins_per_query=15):
        """ì—¬ëŸ¬ ê²€ìƒ‰ì–´ë¡œ ë¶„ì‚° ìˆ˜ì§‘"""
        all_pins = []
        all_seen_urls = set()
        
        for i, query in enumerate(queries):
            print(f"\n=== ê²€ìƒ‰ì–´ {i+1}/{len(queries)}: '{query}' ===")
            
            pins = self.search_pins_improved(query, pins_per_query)
            
            # ì „ì²´ì ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
            unique_pins = []
            for pin in pins:
                if pin['image_url'] not in all_seen_urls:
                    unique_pins.append(pin)
                    all_seen_urls.add(pin['image_url'])
            
            all_pins.extend(unique_pins)
            print(f"'{query}'ì—ì„œ {len(unique_pins)}ê°œ ê³ ìœ  í•€ ìˆ˜ì§‘ (ì¤‘ë³µ {len(pins) - len(unique_pins)}ê°œ ì œê±°)")
            
            # ê²€ìƒ‰ì–´ ê°„ ë”œë ˆì´ (ë´‡ ê°ì§€ ë°©ì§€)
            if i < len(queries) - 1:
                wait_time = random.uniform(8, 12)
                print(f"{wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                time.sleep(wait_time)
        
        return all_pins
    
    def close(self):
        self.driver.quit()

# ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    scraper = ImprovedPinterestScraper()
    
    try:
        # ë‹¤ì–‘í•œ ê²€ìƒ‰ì–´ë¡œ ë¶„ì‚° ìˆ˜ì§‘
        search_queries = [
            "korean men summer fashion",      # ì˜ì–´ ê¸°ë³¸
            "men summer outfit korean",       # ì˜ì–´ ë³€í˜•
            "korean summer street style",     # ìŠ¤íŠ¸ë¦¿ ìŠ¤íƒ€ì¼
            "korean casual summer men",       # ìºì£¼ì–¼ ê°•ì¡°
            "men summer fashion seoul"        # ì„œìš¸ íŒ¨ì…˜
        ]
        
        print("=== ë‹¤ì¤‘ ê²€ìƒ‰ì–´ë¡œ íŒ¨ì…˜ ì´ë¯¸ì§€ ìˆ˜ì§‘ ì‹œì‘ ===")
        all_pins = scraper.multi_query_search(search_queries, pins_per_query=20)
        
        print(f"\nğŸ‰ ì´ {len(all_pins)}ê°œì˜ ê³ ìœ í•œ í•€ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")
        
        # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        output_file = "improved_mens_summer_fashion.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(all_pins, f, ensure_ascii=False, indent=2)
        
        print(f"ê²°ê³¼ê°€ {output_file} íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ê²€ìƒ‰ì–´ë³„ í†µê³„
        query_stats = {}
        for pin in all_pins:
            query = pin['query']
            query_stats[query] = query_stats.get(query, 0) + 1
        
        print("\nğŸ“Š ê²€ìƒ‰ì–´ë³„ ìˆ˜ì§‘ í†µê³„:")
        for query, count in query_stats.items():
            print(f"  - {query}: {count}ê°œ")
        
        # ì²˜ìŒ 5ê°œ ë¯¸ë¦¬ë³´ê¸°
        print("\nğŸ–¼ï¸  ìˆ˜ì§‘ëœ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ê°œ):")
        for i, pin in enumerate(all_pins[:5]):
            print(f"{i+1}. {pin['description'][:60]}...")
            print(f"   ì´ë¯¸ì§€: {pin['image_url']}")
            print(f"   ì¶œì²˜: {pin['query']}")
            print()
            
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        scraper.close()
        print("ë¸Œë¼ìš°ì € ì¢…ë£Œë¨")