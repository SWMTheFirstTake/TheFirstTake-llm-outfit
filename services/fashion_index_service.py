import json
import logging
from typing import Dict, List, Set, Optional
from datetime import datetime
from services.redis_service import redis_service
from services.s3_service import s3_service

logger = logging.getLogger(__name__)

class FashionIndexService:
    """íŒ¨ì…˜ ë°ì´í„° ì¸ë±ì‹± ë° ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•œ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.index_prefix = "fashion_index"
        self.metadata_prefix = "fashion_metadata"
        
    def build_indexes(self, force_rebuild: bool = False) -> Dict[str, int]:
        """S3ì˜ ëª¨ë“  JSON íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        print("ğŸ” íŒ¨ì…˜ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘...")
        
        if force_rebuild:
            print("ğŸ”„ ê°•ì œ ì¬êµ¬ì¶• ëª¨ë“œ: ê¸°ì¡´ ì¸ë±ìŠ¤ ì™„ì „ ì‚­ì œ")
            self._clear_indexes()
            return self._build_all_indexes()
        else:
            print("ğŸ”„ ì¦ë¶„ ì—…ë°ì´íŠ¸ ëª¨ë“œ: ìƒˆë¡œìš´ íŒŒì¼ë§Œ ì¸ë±ì‹±")
            return self._build_incremental_indexes()
    
    def _build_all_indexes(self) -> Dict[str, int]:
        """ì „ì²´ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
        try:
            # S3ì—ì„œ ëª¨ë“  JSON íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
            json_files = s3_service.list_json_files()
            if not json_files:
                print("âŒ S3ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
                return {"total": 0, "indexed": 0}
            
            indexed_count = 0
            total_count = len(json_files)
            
            for file_info in json_files:
                try:
                    # JSON ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                    json_content = s3_service.get_json_content(file_info['filename'])
                    
                    # ì¸ë±ìŠ¤ êµ¬ì¶•
                    self._index_file(file_info['filename'], json_content, file_info['s3_url'])
                    indexed_count += 1
                    
                    if indexed_count % 10 == 0:
                        print(f"   ğŸ“Š ì§„í–‰ë¥ : {indexed_count}/{total_count}")
                        
                except Exception as e:
                    print(f"âŒ íŒŒì¼ ì¸ë±ì‹± ì‹¤íŒ¨: {file_info['filename']} - {e}")
                    continue
            
            print(f"âœ… ì „ì²´ ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {indexed_count}/{total_count}ê°œ íŒŒì¼")
            return {"total": total_count, "indexed": indexed_count}
            
        except Exception as e:
            print(f"âŒ ì „ì²´ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {e}")
            logger.error(f"ì „ì²´ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {e}")
            return {"total": 0, "indexed": 0}
    
    def _build_incremental_indexes(self) -> Dict[str, int]:
        """ì¦ë¶„ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ (ìƒˆë¡œìš´ íŒŒì¼ë§Œ)"""
        try:
            # S3ì—ì„œ ëª¨ë“  JSON íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
            s3_files = s3_service.list_json_files()
            if not s3_files:
                print("âŒ S3ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
                return {"total": 0, "indexed": 0, "updated": 0}
            
            # Redisì— ì´ë¯¸ ì¸ë±ì‹±ëœ íŒŒì¼ë“¤ í™•ì¸
            existing_metadata_keys = redis_service.keys(f"{self.metadata_prefix}:*")
            existing_files = set()
            for key in existing_metadata_keys:
                filename = key.replace(f"{self.metadata_prefix}:", "")
                existing_files.add(filename)
            
            print(f"ğŸ“Š ê¸°ì¡´ ì¸ë±ì‹±ëœ íŒŒì¼: {len(existing_files)}ê°œ")
            print(f"ğŸ“Š S3 ì „ì²´ íŒŒì¼: {len(s3_files)}ê°œ")
            
            # ìƒˆë¡œìš´ íŒŒì¼ë“¤ ì°¾ê¸°
            s3_filenames = {file_info['filename'] for file_info in s3_files}
            new_files = s3_filenames - existing_files
            updated_files = set()
            
            print(f"ğŸ†• ìƒˆë¡œ ì¶”ê°€ëœ íŒŒì¼: {len(new_files)}ê°œ")
            
            # ìƒˆë¡œìš´ íŒŒì¼ë“¤ ì¸ë±ì‹±
            indexed_count = 0
            for file_info in s3_files:
                if file_info['filename'] in new_files:
                    try:
                        # JSON ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                        json_content = s3_service.get_json_content(file_info['filename'])
                        
                        # ì¸ë±ìŠ¤ êµ¬ì¶•
                        self._index_file(file_info['filename'], json_content, file_info['s3_url'])
                        indexed_count += 1
                        
                        if indexed_count % 5 == 0:
                            print(f"   ğŸ“Š ìƒˆ íŒŒì¼ ì¸ë±ì‹± ì§„í–‰ë¥ : {indexed_count}/{len(new_files)}")
                            
                    except Exception as e:
                        print(f"âŒ ìƒˆ íŒŒì¼ ì¸ë±ì‹± ì‹¤íŒ¨: {file_info['filename']} - {e}")
                        continue
            
            # ê¸°ì¡´ íŒŒì¼ë“¤ì˜ ì—…ë°ì´íŠ¸ í™•ì¸ (íƒ€ì„ìŠ¤íƒ¬í”„ ë¹„êµ)
            for file_info in s3_files:
                if file_info['filename'] in existing_files:
                    try:
                        # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
                        existing_metadata = redis_service.get_json(f"{self.metadata_prefix}:{file_info['filename']}")
                        if existing_metadata:
                            existing_timestamp = existing_metadata.get('timestamp', '')
                            
                            # S3 íŒŒì¼ì˜ ìµœì‹  íƒ€ì„ìŠ¤íƒ¬í”„ í™•ì¸
                            json_content = s3_service.get_json_content(file_info['filename'])
                            s3_timestamp = json_content.get('analysis_timestamp', '')
                            
                            # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ë‹¤ë¥´ë©´ ì—…ë°ì´íŠ¸
                            if existing_timestamp != s3_timestamp:
                                self._index_file(file_info['filename'], json_content, file_info['s3_url'])
                                updated_files.add(file_info['filename'])
                                
                    except Exception as e:
                        print(f"âŒ íŒŒì¼ ì—…ë°ì´íŠ¸ í™•ì¸ ì‹¤íŒ¨: {file_info['filename']} - {e}")
                        continue
            
            print(f"âœ… ì¦ë¶„ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ:")
            print(f"   - ìƒˆë¡œ ì¸ë±ì‹±ëœ íŒŒì¼: {len(new_files)}ê°œ")
            print(f"   - ì—…ë°ì´íŠ¸ëœ íŒŒì¼: {len(updated_files)}ê°œ")
            print(f"   - ì´ ì²˜ë¦¬ëœ íŒŒì¼: {len(new_files) + len(updated_files)}ê°œ")
            
            return {
                "total": len(s3_files),
                "indexed": len(new_files),
                "updated": len(updated_files),
                "existing": len(existing_files)
            }
            
        except Exception as e:
            print(f"âŒ ì¦ë¶„ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            logger.error(f"ì¦ë¶„ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return {"total": 0, "indexed": 0, "updated": 0}
    
    def _index_file(self, filename: str, content: dict, s3_url: str):
        """ë‹¨ì¼ íŒŒì¼ì„ ì¸ë±ì‹±"""
        try:
            extracted_items = content.get('extracted_items', {})
            situations = content.get('situations', [])
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata = {
                "filename": filename,
                "s3_url": s3_url,
                "situations": situations,
                "items": self._extract_item_summary(extracted_items),
                "styling_methods": extracted_items.get('styling_methods', {}),
                "timestamp": content.get('analysis_timestamp', ''),
                "updated_at": content.get('updated_at', '')
            }
            
            # Redisì— ë©”íƒ€ë°ì´í„° ì €ì¥
            redis_service.set_json(f"{self.metadata_prefix}:{filename}", metadata)
            
            # ìƒí™©ë³„ ì¸ë±ìŠ¤
            for situation in situations:
                self._add_to_index(f"situation:{situation}", filename)
            
            # ì•„ì´í…œë³„ ì¸ë±ìŠ¤
            self._index_items(filename, extracted_items)
            
            # ìƒ‰ìƒë³„ ì¸ë±ìŠ¤
            self._index_colors(filename, extracted_items)
            
            # ìŠ¤íƒ€ì¼ë§ ë°©ë²•ë³„ ì¸ë±ìŠ¤
            self._index_styling_methods(filename, extracted_items)
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì¸ë±ì‹± ì¤‘ ì—ëŸ¬: {filename} - {e}")
    
    def _extract_item_summary(self, extracted_items: dict) -> dict:
        """ì•„ì´í…œ ìš”ì•½ ì •ë³´ ì¶”ì¶œ"""
        summary = {}
        
        for category, item_info in extracted_items.items():
            if isinstance(item_info, dict):
                summary[category] = {
                    "item": item_info.get('item', ''),
                    "color": item_info.get('color', ''),
                    "fit": item_info.get('fit', ''),
                    "material": item_info.get('material', '')
                }
        
        return summary
    
    def _index_items(self, filename: str, extracted_items: dict):
        """ì•„ì´í…œë³„ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        for category, item_info in extracted_items.items():
            if isinstance(item_info, dict):
                item_name = item_info.get('item', '').lower()
                if item_name:
                    # ì•„ì´í…œëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
                    keywords = self._extract_keywords(item_name)
                    for keyword in keywords:
                        self._add_to_index(f"item:{keyword}", filename)
    
    def _index_colors(self, filename: str, extracted_items: dict):
        """ìƒ‰ìƒë³„ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        colors = set()
        
        for category, item_info in extracted_items.items():
            if isinstance(item_info, dict):
                color = item_info.get('color', '').lower()
                if color:
                    colors.add(color)
        
        for color in colors:
            self._add_to_index(f"color:{color}", filename)
    
    def _index_styling_methods(self, filename: str, extracted_items: dict):
        """ìŠ¤íƒ€ì¼ë§ ë°©ë²•ë³„ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        styling_methods = extracted_items.get('styling_methods', {})
        
        for method_key, method_value in styling_methods.items():
            if isinstance(method_value, str) and method_value:
                keywords = self._extract_keywords(method_value.lower())
                for keyword in keywords:
                    self._add_to_index(f"styling:{keyword}", filename)
    
    def _extract_keywords(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ì‚¬ìš© ê°€ëŠ¥)
        keywords = []
        
        # ì¼ë°˜ì ì¸ íŒ¨ì…˜ í‚¤ì›Œë“œë“¤
        fashion_keywords = [
            "ë‹ˆíŠ¸", "ë°ë‹˜", "ê°€ì£½", "ë©´", "ì‹¤í¬", "ìš¸", "í´ë¦¬ì—ìŠ¤í„°",
            "ê¸´íŒ”", "ë°˜íŒ”", "ì™€ì´ë“œ", "ìŠ¤í‚¤ë‹ˆ", "ë ˆê·¤ëŸ¬", "ì˜¤ë²„í•", "ìŠ¬ë¦¼",
            "ë¸”ë™", "í™”ì´íŠ¸", "ê·¸ë ˆì´", "ë¸Œë¼ìš´", "ë„¤ì´ë¹„", "ë² ì´ì§€",
            "í‹°ì…”ì¸ ", "ì…”ì¸ ", "ë‹ˆíŠ¸", "ìŠ¤ì›¨í„°", "í›„ë“œí‹°", "ë§¨íˆ¬ë§¨",
            "ìŠ¬ë™ìŠ¤", "ì²­ë°”ì§€", "íŒ¬ì¸ ", "ë°˜ë°”ì§€", "ìŠ¤ì»¤íŠ¸",
            "ìŠ¤ë‹ˆì»¤ì¦ˆ", "ë¡œí¼", "ì˜¥ìŠ¤í¬ë“œ", "ë¶€ì¸ ", "ìƒŒë“¤",
            "ë„£ê¸°", "í„±", "í•", "ì‹¤ë£¨ì—£", "ë°¸ëŸ°ìŠ¤"
        ]
        
        for keyword in fashion_keywords:
            if keyword in text:
                keywords.append(keyword)
        
        return keywords
    
    def _add_to_index(self, index_key: str, filename: str):
        """ì¸ë±ìŠ¤ì— íŒŒì¼ ì¶”ê°€"""
        try:
            redis_key = f"{self.index_prefix}:{index_key}"
            redis_service.sadd(redis_key, filename)
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ ì¶”ê°€ ì‹¤íŒ¨: {index_key} - {e}")
    
    def _clear_indexes(self):
        """ê¸°ì¡´ ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
        try:
            # ì¸ë±ìŠ¤ í‚¤ë“¤ ì°¾ê¸°
            pattern = f"{self.index_prefix}:*"
            keys = redis_service.keys(pattern)
            
            if keys:
                redis_service.delete(*keys)
                print(f"ğŸ—‘ï¸ ê¸°ì¡´ ì¸ë±ìŠ¤ {len(keys)}ê°œ ì‚­ì œ")
            
            # ë©”íƒ€ë°ì´í„° í‚¤ë“¤ ì°¾ê¸°
            pattern = f"{self.metadata_prefix}:*"
            keys = redis_service.keys(pattern)
            
            if keys:
                redis_service.delete(*keys)
                print(f"ğŸ—‘ï¸ ê¸°ì¡´ ë©”íƒ€ë°ì´í„° {len(keys)}ê°œ ì‚­ì œ")
                
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def search_by_situation(self, situation: str, limit: int = 20) -> List[dict]:
        """ìƒí™©ë³„ ê²€ìƒ‰"""
        try:
            index_key = f"situation:{situation.lower()}"
            filenames = redis_service.smembers(f"{self.index_prefix}:{index_key}")
            
            results = []
            for filename in list(filenames)[:limit]:
                metadata = self._get_metadata(filename)
                if metadata:
                    results.append(metadata)
            
            return results
        except Exception as e:
            print(f"âŒ ìƒí™©ë³„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def search_by_item(self, item_keyword: str, limit: int = 20) -> List[dict]:
        """ì•„ì´í…œë³„ ê²€ìƒ‰"""
        try:
            index_key = f"item:{item_keyword.lower()}"
            filenames = redis_service.smembers(f"{self.index_prefix}:{index_key}")
            
            results = []
            for filename in list(filenames)[:limit]:
                metadata = self._get_metadata(filename)
                if metadata:
                    results.append(metadata)
            
            return results
        except Exception as e:
            print(f"âŒ ì•„ì´í…œë³„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def search_by_color(self, color: str, limit: int = 20) -> List[dict]:
        """ìƒ‰ìƒë³„ ê²€ìƒ‰"""
        try:
            index_key = f"color:{color.lower()}"
            filenames = redis_service.smembers(f"{self.index_prefix}:{index_key}")
            
            results = []
            for filename in list(filenames)[:limit]:
                metadata = self._get_metadata(filename)
                if metadata:
                    results.append(metadata)
            
            return results
        except Exception as e:
            print(f"âŒ ìƒ‰ìƒë³„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def search_by_styling(self, styling_keyword: str, limit: int = 20) -> List[dict]:
        """ìŠ¤íƒ€ì¼ë§ ë°©ë²•ë³„ ê²€ìƒ‰"""
        try:
            index_key = f"styling:{styling_keyword.lower()}"
            filenames = redis_service.smembers(f"{self.index_prefix}:{index_key}")
            
            results = []
            for filename in list(filenames)[:limit]:
                metadata = self._get_metadata(filename)
                if metadata:
                    results.append(metadata)
            
            return results
        except Exception as e:
            print(f"âŒ ìŠ¤íƒ€ì¼ë§ë³„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def advanced_search(self, criteria: dict, limit: int = 20) -> List[dict]:
        """ê³ ê¸‰ ê²€ìƒ‰ (ì—¬ëŸ¬ ì¡°ê±´ ì¡°í•©)"""
        try:
            all_filenames = set()
            first_search = True
            
            # ê° ì¡°ê±´ë³„ë¡œ ê²€ìƒ‰
            if 'situations' in criteria and criteria['situations']:
                for situation in criteria['situations']:
                    filenames = redis_service.smembers(f"{self.index_prefix}:situation:{situation.lower()}")
                    if first_search:
                        all_filenames = set(filenames)
                        first_search = False
                    else:
                        all_filenames = all_filenames.intersection(set(filenames))
            
            if 'items' in criteria and criteria['items']:
                for item in criteria['items']:
                    filenames = redis_service.smembers(f"{self.index_prefix}:item:{item.lower()}")
                    if first_search:
                        all_filenames = set(filenames)
                        first_search = False
                    else:
                        all_filenames = all_filenames.intersection(set(filenames))
            
            if 'colors' in criteria and criteria['colors']:
                for color in criteria['colors']:
                    filenames = redis_service.smembers(f"{self.index_prefix}:color:{color.lower()}")
                    if first_search:
                        all_filenames = set(filenames)
                        first_search = False
                    else:
                        all_filenames = all_filenames.intersection(set(filenames))
            
            if 'styling' in criteria and criteria['styling']:
                for styling in criteria['styling']:
                    filenames = redis_service.smembers(f"{self.index_prefix}:styling:{styling.lower()}")
                    if first_search:
                        all_filenames = set(filenames)
                        first_search = False
                    else:
                        all_filenames = all_filenames.intersection(set(filenames))
            
            # ê²€ìƒ‰ ì¡°ê±´ì´ ì—†ê±°ë‚˜ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°, ì „ì²´ íŒŒì¼ì—ì„œ ëœë¤ ì„ íƒ
            if not all_filenames:
                print("âš ï¸ ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” íŒŒì¼ì´ ì—†ì–´ ì „ì²´ íŒŒì¼ì—ì„œ ì„ íƒ")
                # ì „ì²´ ë©”íƒ€ë°ì´í„°ì—ì„œ ëœë¤ ì„ íƒ
                all_metadata_keys = redis_service.keys(f"{self.metadata_prefix}:*")
                if all_metadata_keys:
                    import random
                    selected_keys = random.sample(all_metadata_keys, min(limit, len(all_metadata_keys)))
                    all_filenames = {key.replace(f"{self.metadata_prefix}:", "") for key in selected_keys}
            
            # ê²°ê³¼ ë°˜í™˜
            results = []
            for filename in list(all_filenames)[:limit]:
                metadata = self._get_metadata(filename)
                if metadata:
                    results.append(metadata)
            
            return results
            
        except Exception as e:
            print(f"âŒ ê³ ê¸‰ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _get_metadata(self, filename: str) -> Optional[dict]:
        """íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
        try:
            metadata = redis_service.get_json(f"{self.metadata_prefix}:{filename}")
            return metadata
        except Exception as e:
            print(f"âŒ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {filename} - {e}")
            return None
    
    def get_index_stats(self) -> dict:
        """ì¸ë±ìŠ¤ í†µê³„ ì •ë³´"""
        try:
            stats = {
                "total_files": 0,
                "situation_indexes": 0,
                "item_indexes": 0,
                "color_indexes": 0,
                "styling_indexes": 0
            }
            
            # ì „ì²´ íŒŒì¼ ìˆ˜
            pattern = f"{self.metadata_prefix}:*"
            keys = redis_service.keys(pattern)
            stats["total_files"] = len(keys)
            
            # ê° ì¸ë±ìŠ¤ íƒ€ì…ë³„ ê°œìˆ˜
            index_types = ["situation", "item", "color", "styling"]
            for index_type in index_types:
                pattern = f"{self.index_prefix}:{index_type}:*"
                keys = redis_service.keys(pattern)
                stats[f"{index_type}_indexes"] = len(keys)
            
            return stats
            
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
fashion_index_service = FashionIndexService() 